{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import glob\n",
    "import os \n",
    "import itertools\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from collections.abc import MutableMapping\n",
    "from IPython import display as ICD\n",
    "from decimal import Decimal\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import torch\n",
    "\n",
    "from paper_utils.plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_dir = '../plotly'\n",
    "datasets = ['CoraML', 'CiteSeer', 'PubMed', 'AmazonPhotos', 'AmazonComputers', 'CoauthorCS', 'CoauthorPhysics']\n",
    "param_keys = ['dist_reg', 'orig_dist_reg', 'KNN_K', 'dist_sigma', 'dist_embedding_beta', 'activation_type', 'entropy_reg', 'lipschitz_reg', 'lipschitz_init', 'num_layers']\n",
    "dataset_keys = ['dataset', ]\n",
    "# result_keys = ['val_accuracy', 'test_ood_detection_epistemic_auroc', 'test_accuracy', 'confidence_epistemic_auroc']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert ray_result files to a compiled csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = os.listdir(\"../ray_results/\")\n",
    "for a_dir in directories:\n",
    "    if \".~lock\" in a_dir:\n",
    "        continue\n",
    "    if not a_dir.endswith(\".csv\") and \"hidden\" not in a_dir:\n",
    "        file_to_write = f'../ray_results/{a_dir}.csv'\n",
    "        if not os.path.exists(file_to_write):\n",
    "            print(file_to_write + \" is writing!\")\n",
    "            df = get_df(a_dir)\n",
    "            df.to_csv(f'../ray_results/{a_dir}.csv')\n",
    "            print('Finished')\n",
    "        else:\n",
    "            pass\n",
    "            print(file_to_write + \" already exists!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = sorted(glob.glob(\"../ray_results/*.csv\"))\n",
    "results = []\n",
    "full_results = []\n",
    "   \n",
    "outputs_config = [\n",
    "    'config.model.activation_type', 'config.model.entropy_reg', 'config.model.dist_reg', 'config.model.orig_dist_reg', 'config.model.decoder_reg'\n",
    "]\n",
    "outputs_loc = [\n",
    "            'val_CE', 'test_accuracy', 'test_ood_detection_aleatoric_auroc', 'test_ood_detection_epistemic_auroc', 'test_ood_detection_features_auroc', \n",
    "            'test_ood_detection_aleatoric_apr', 'test_ood_detection_epistemic_apr', 'test_ood_detection_features_apr']\n",
    "outputs_miss = [\n",
    "    'val_CE', 'test_accuracy', 'test_confidence_aleatoric_auroc', 'test_confidence_epistemic_auroc', 'test_confidence_aleatoric_apr', 'test_confidence_epistemic_apr'\n",
    "]\n",
    "out = outputs_config + outputs_loc\n",
    "\n",
    "avoid_words = ['sqrt', 'final', 'isolated', 'budget', 'dice', 'preserving', 'lipschitz', 'stress', 'leave', 'best']\n",
    "# avoid_words = []\n",
    "big_full = []\n",
    "\n",
    "for a_trial in trials:\n",
    "    filename = os.path.basename(a_trial)\n",
    "    name, _ = os.path.splitext(filename)\n",
    "    df = pd.read_csv(a_trial)\n",
    "    df = df.drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "    if 'decoder' not in name.casefold():\n",
    "        continue\n",
    "    print(name)\n",
    "    \n",
    "    if all([a_avoidable not in name.casefold() for a_avoidable in avoid_words]):\n",
    "        try: \n",
    "            result, full_result = get_best_result(df, 'config.data.dataset', 'val_CE', outputs_config + outputs_loc)\n",
    "        except:\n",
    "            result, full_result = get_best_result(df, 'config.data.dataset', 'val_CE', outputs_config + outputs_miss)\n",
    "            \n",
    "        if len(result) == 0:\n",
    "            continue\n",
    "\n",
    "        result['name'] = name\n",
    "        full_result['name'] = name\n",
    "\n",
    "        results.append(result)\n",
    "        full_results.append(full_result)\n",
    "        big_full.append(df)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # for y in ['accuracy', ]:#, 'test_ood_detection_epistemic_auroc', 'test_confidence_aleatoric_auroc', 'test_confidence_aleatoric_apr']:\n",
    "    #     print(name)\n",
    "    #     plot_data(plotly_dir, df, name, y, 'tune-reg', as_line=True, log_x=True, \n",
    "    #                 facet_x='config.data.dataset', facet_y='config.model.activation_type', line_dash=None)\n",
    "\n",
    "    # if \"Isolated\" in a_trial or \"Leave_Out_Classes\" in a_trial:\n",
    "    #     df = generate_latex_table(df, ['config.data.dataset'], ['test_ood_detection_aleatoric_auroc', 'test_ood_detection_epistemic_auroc', 'test_accuracy'])\n",
    "    #     ICD.display(df)\n",
    "    \n",
    "results = pd.concat(results)\n",
    "full_results = pd.concat(full_results)\n",
    "results.columns = map(lambda s:s.replace(\"Confidence\", \"\").strip(), results.columns)\n",
    "pd.set_option('display.max_rows', results.shape[0]+1) #  'w/o Net AUROC' 'w/o Net APR'\n",
    "for a_key in ['Accuracy', 'Alea AUROC', 'Epist AUROC', 'Alea APR', 'Epist APR']:\n",
    "    results[a_key] = results[a_key].apply(lambda x: np.round(x*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_key(a_partial_key):\n",
    "    keys = df.columns\n",
    "    return [a_key for a_key in keys if a_partial_key in a_key]\n",
    "print(get_partial_key('val_CE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_full = pd.concat(big_full)\n",
    "big_full = big_full[['PubMed' in a_name for a_name in big_full['config.data.dataset']]]\n",
    "big_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = results.sort_values(['Dataset', \"CE\"])\n",
    "# dfs = [x for _, x in results.groupby('Dataset')]\n",
    "# all_dfs = []\n",
    "# for a_df in dfs:\n",
    "#     # graph_row = a_df[['Graph' in a_name for a_name in a_df.name]].iloc[0]\n",
    "#     # entropy_row = a_df[['Entropy' in a_name for a_name in a_df.name]].iloc[0]\n",
    "#     entropy_row = a_df[['Decoder' in a_name for a_name in a_df.name]].iloc[0]\n",
    "#     df = pd.DataFrame([big_full, entropy_row], columns=big_full.keys())\n",
    "#     all_dfs.append(df)\n",
    "    \n",
    "# ICD.display(pd.concat(all_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gpn2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd7c549fabb2b127a1e4b21f6588d14147668e20339c0f349401ff861a5eefd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
